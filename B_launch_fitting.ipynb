{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import types\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pybads.bads import BADS\n",
    "from itertools import chain\n",
    "from pyvbmc import VBMC\n",
    "from functools import partial\n",
    "import time\n",
    "from joblib import Parallel, delayed, cpu_count\n",
    "import os\n",
    "import pickle\n",
    "import scipy\n",
    "import submitit\n",
    "import runpy\n",
    "from pyvbmc import priors\n",
    "import importlib\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded:\n",
      "0. SASSS_Omega_standard\n",
      "1. SASSS_Omega_splitBias\n",
      "2. SASSS_Omega_splitBeta\n",
      "3. SASonly\n"
     ]
    }
   ],
   "source": [
    "## Select and load model space\n",
    "#\n",
    "model_space='basic_modelspace'\n",
    "model_module = importlib.import_module(f\"models.{model_space}\")\n",
    "#\n",
    "model_list, bounds_list, plausible_bounds_list, all_models, prior_shapes, default_values=model_module.main()\n",
    "#\n",
    "nstates, nactions, nfutures = (3,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select dataset\n",
    "compiled_datadir='compiled_data'\n",
    "dataset_name='dev'\n",
    "\n",
    "## Load data\n",
    "data_file=os.path.join(compiled_datadir,dataset_name, 'dataset.pkl')\n",
    "#\n",
    "df_full=pd.read_pickle(data_file)\n",
    "\n",
    "# Load metadata\n",
    "metadata_file=os.path.join(compiled_datadir,dataset_name, 'metadata.pkl')\n",
    "with open(metadata_file, 'rb') as file:\n",
    "    metadata = pickle.load(file)\n",
    "\n",
    "\n",
    "### \n",
    "fitToolbox='pybads' # pyvbmc or pybads (note that vbmc write an additional output structure for each model)\n",
    "\n",
    "### Other fit options\n",
    "parallel_job=False\n",
    "parallel_mode='slurm' # may be 'joblib' for local parallelization or 'slurm' for cluster parallelization\n",
    "parallel_maxjobs=420\n",
    "robustMode=True\n",
    "verbose=False\n",
    "\n",
    "priors_constrainFit=True\n",
    "# reset mode\n",
    "reset_mode='all'\n",
    "\n",
    "### Development options\n",
    "devParticipants=[] # if not empty: will restrict to this list of subjects\n",
    "\n",
    "### Set fitting options\n",
    "badsOptions={\n",
    "    'max_iter':50, \n",
    "    'max_fun_evals':200,\n",
    "    'display': \"off\",\n",
    "    'nrestart': 2,\n",
    "    'maxrestart': 2,\n",
    "}\n",
    "vbmcPyBadsInitOptions={\n",
    "    'max_iter':25,\n",
    "    'max_fun_evals':250,\n",
    "    'display': \"off\",\n",
    "}\n",
    "vbmcOptions={\n",
    "    'max_iter':50,\n",
    "    'max_fun_evals':250,\n",
    "    'display': \"off\",\n",
    "    'nrestart': 4,\n",
    "    'maxrestart': 8,\n",
    "}\n",
    "if parallel_job==False:\n",
    "    vbmcOptions['display']=\"iter\"\n",
    "    badsOptions['display']=\"iter\"\n",
    "    \n",
    "    \n",
    "### Make output folder\n",
    "fit_folder='model_fits'\n",
    "if fitToolbox=='pybads':\n",
    "    fit_name = f'{model_space}_bads_it{badsOptions[\"max_iter\"]}_funit{badsOptions[\"max_fun_evals\"]}_nres{badsOptions[\"nrestart\"]}_reset{reset_mode}'\n",
    "elif fitToolbox=='pyvbmc':\n",
    "    fit_name = f'{model_space}_vbmc_it{vbmcOptions[\"max_iter\"]}_funit{vbmcOptions[\"max_fun_evals\"]}_nres{vbmcOptions[\"nrestart\"]}_reset{reset_mode}'\n",
    "    \n",
    "fit_folder=os.path.join(fit_folder,fit_name)\n",
    "if not os.path.isdir(fit_folder):\n",
    "    os.makedirs(fit_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA TO BE FITTED\n",
      "{'SAmap': [[1, 2], [0, 2], [0, 1]],\n",
      " 'dataset_name': 'dev',\n",
      " 'folder_compiled_data': 'compiled_data',\n",
      " 'folder_logfiles': 'logfiles',\n",
      " 'included_participants': ['1', '1bis'],\n",
      " 'included_runs': ['1', '2', '3'],\n",
      " 'included_sessions': ['1', '2']}\n"
     ]
    }
   ],
   "source": [
    "print('DATA TO BE FITTED')\n",
    "pprint(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "### fit all the data with all agents\n",
    "\n",
    "# initialize the complete output structure\n",
    "results_df=pd.DataFrame()\n",
    "\n",
    "#\n",
    "if len(devParticipants)>0:\n",
    "    df_full = df_full.loc[np.isin(df_full['participant'],devParticipants),:]\n",
    "    participants=devParticipants\n",
    "else:\n",
    "  participants=metadata['included_participants']\n",
    "  \n",
    "massive_jobstruct=[]\n",
    "massive_jobs_id=[]\n",
    "massive_jobs_count=0\n",
    "\n",
    "if fitToolbox=='pybads':\n",
    "    nrestart=badsOptions.pop('nrestart')\n",
    "    maxrestart=badsOptions.pop('maxrestart')\n",
    "else:\n",
    "    nrestart=vbmcOptions.pop('nrestart')\n",
    "    maxrestart=vbmcOptions.pop('maxrestart')\n",
    "    \n",
    "    \n",
    "for m, model in enumerate(model_list):\n",
    "            \n",
    "    nparameters=1+np.max([max(model['parameter_mapping'][mapval]) for mapval in model['parameter_mapping'] if isinstance(model['parameter_mapping'][mapval],list) ])\n",
    "    lb=np.zeros(nparameters)\n",
    "    hb=np.zeros(nparameters)\n",
    "    plb=np.zeros(nparameters)\n",
    "    phb=np.zeros(nparameters)\n",
    "    if priors_constrainFit:\n",
    "      prior_array=[]\n",
    "    else:\n",
    "      prior_array=None\n",
    "    for prm in model['parameter_mapping']:\n",
    "        if isinstance(model['parameter_mapping'][prm], list):\n",
    "          for param_ind in model['parameter_mapping'][prm]:\n",
    "            lb[param_ind]=model['bounds_list'][prm][0]\n",
    "            hb[param_ind]=model['bounds_list'][prm][1]\n",
    "            plb[param_ind]=model['plausible_bounds_list'][prm][0]\n",
    "            phb[param_ind]=model['plausible_bounds_list'][prm][1]\n",
    "            if priors_constrainFit:\n",
    "              if prior_shapes[prm]=='UniformBox':\n",
    "                  prior_array.append(priors.UniformBox(lb[param_ind],hb[param_ind]))\n",
    "              elif prior_shapes[prm]=='Trapezoidal':\n",
    "                  prior_array.append(priors.Trapezoidal(lb[param_ind], plb[param_ind],  phb[param_ind],hb[param_ind]))\n",
    "              elif prior_shapes[prm]=='SmoothBox':\n",
    "                  prior_array.append(priors.SmoothBox(plb[param_ind], phb[param_ind],0.8))\n",
    "            \n",
    "    mappingParam=model['parameter_mapping']\n",
    "    extraParam=model['parameter_preset']\n",
    "    agent=model['agent']\n",
    "    \n",
    "    def pyBADSparallel_func(fitId):\n",
    "      \n",
    "      if parallel_job and parallel_mode=='slurm':\n",
    "          print(submitit.JobEnvironment())\n",
    "          \n",
    "      vposteriors=[]\n",
    "      \n",
    "      df_subdata=df_full.loc[df_full['participant']==fitId,:].copy(deep=True)\n",
    "\n",
    "      npoints=np.sum(df_subdata['state_choice']>=0)\n",
    "      \n",
    "      def single_fit_run(seed, model, fitId, mappingParam, prior_array, phb, plb, lb, hb,\n",
    "                        fitToolbox, badsOptions, vbmcOptions, vbmcPyBadsInitOptions,\n",
    "                        df_subdata):\n",
    "          \n",
    "          np.random.seed(seed)\n",
    "          \n",
    "          try:\n",
    "              paramDim = len(phb)\n",
    "              param0 = plb + np.random.uniform(size=(paramDim,)) * (phb - plb)\n",
    "\n",
    "              agent = model['agent'](model['factors'], nstates, nactions, nfutures)\n",
    "              agent.init(model['parameter_preset'])\n",
    "\n",
    "              funforfit = partial(agent.fit,\n",
    "                                  mappingParam=mappingParam,\n",
    "                                  arrayS=df_subdata['state'].values,\n",
    "                                  arrayA=df_subdata['action'].values,\n",
    "                                  arraySnext=df_subdata['next_state'].values,\n",
    "                                  arrayR=df_subdata['reward'].values,\n",
    "                                  arrayType=df_subdata['trial_tag_bool'].values,\n",
    "                                  arrayMissed=df_subdata['missed'].values,\n",
    "                                  arrayPrediction=df_subdata['state_choice'].values-1,\n",
    "                                  arraySplit=df_subdata['visit'].values-1,\n",
    "                                  resets=df_subdata['newblock'].values,\n",
    "                                  returnMemory=False,\n",
    "                                  prior_array=None,\n",
    "                                  default_values=model['default_values'])\n",
    "\n",
    "              if fitToolbox == 'pybads':\n",
    "                  bads = BADS(funforfit, param0, lb, hb, plb, phb, options=badsOptions)\n",
    "                  optimize_result = bads.optimize()\n",
    "                  fitted = np.array(optimize_result['x'])\n",
    "                  nll = optimize_result['fval']\n",
    "              else:\n",
    "                  bads = BADS(funforfit, param0, lb, hb, plb, phb, options=vbmcPyBadsInitOptions)\n",
    "                  optimize_result = bads.optimize()\n",
    "                  vbmc = VBMC(funforfit, optimize_result['x'], lb, hb, plb, phb,\n",
    "                              options=vbmcOptions, prior=prior_array)\n",
    "                  vp, optimize_result = vbmc.optimize()\n",
    "                  fitted = vp.moments()\n",
    "                  nll = -optimize_result['elbo']\n",
    "\n",
    "              return (fitted, nll)\n",
    "          \n",
    "          except Exception as e:\n",
    "              print(\"An error with fitId:\", fitId)\n",
    "              print(\"An error occurred:\", e)\n",
    "              print(\"Type of exception:\", type(e))\n",
    "              return (np.full(len(phb), np.nan), np.nan)\n",
    "\n",
    "\n",
    "      # --- Setup for Parallel Execution ---\n",
    "      fitNLL = np.full((maxrestart,), np.nan)\n",
    "      fittedParameters = np.full((maxrestart, nparameters), np.nan)\n",
    "\n",
    "      seeds = np.random.randint(0, 1e6, size=maxrestart)\n",
    "\n",
    "      results = Parallel(n_jobs=-1)(\n",
    "          delayed(single_fit_run)(\n",
    "              seed, model, fitId, mappingParam, prior_array,\n",
    "              phb, plb, lb, hb,\n",
    "              fitToolbox, badsOptions, vbmcOptions, vbmcPyBadsInitOptions,\n",
    "              df_subdata\n",
    "          ) for seed in seeds\n",
    "      )\n",
    "\n",
    "      # Collect valid results up to `nrestart`\n",
    "      rep = 0\n",
    "      for i, (fitted, nll) in enumerate(results):\n",
    "          if not np.any(np.isnan(fitted)) and not np.isnan(nll):\n",
    "              fittedParameters[rep, :] = fitted\n",
    "              fitNLL[rep] = nll\n",
    "              rep += 1\n",
    "              if verbose:\n",
    "                print(f'rep {rep}')\n",
    "                print(fitNLL)\n",
    "              if rep >= nrestart:\n",
    "                  break\n",
    "\n",
    "      # --- Final selection ---\n",
    "      try:\n",
    "          min_index = pd.Series(fitNLL).idxmin()\n",
    "          bestNLL = fitNLL[min_index]\n",
    "          agent = model['agent'](model['factors'], nstates, nactions, nfutures)\n",
    "          agent.init(model['parameter_preset'])\n",
    "          \n",
    "          bestNLL, priorNLL, agentMemory, mappingX = agent.fit(\n",
    "              fittedParameters[min_index, :],\n",
    "              mappingParam=mappingParam,\n",
    "              arrayS=df_subdata['state'].values,\n",
    "              arrayA=df_subdata['action'].values,\n",
    "              arraySnext=df_subdata['next_state'].values,\n",
    "              arrayR=df_subdata['reward'].values,\n",
    "              arrayType=df_subdata['trial_tag_bool'].values,\n",
    "              arrayMissed=df_subdata['missed'].values,\n",
    "              arrayPrediction=df_subdata['state_choice'].values-1,\n",
    "              arraySplit=df_subdata['visit'].values-1,\n",
    "              resets=np.where(df_subdata['newblock'].values==1)[0],\n",
    "              returnMemory=True,\n",
    "              prior_array=None,\n",
    "              default_values=model['default_values'],\n",
    "          )\n",
    "          if verbose:\n",
    "            print(fitId, bestNLL, bestAIC, bestBIC, priorNLL, fittedParameters[min_index,:], 100*(rep/maxrestart))\n",
    "\n",
    "          bestAIC = 2*nparameters + 2*bestNLL\n",
    "          bestBIC = np.log(npoints)*nparameters + 2*bestNLL\n",
    "          return bestNLL, bestAIC, bestBIC, priorNLL, fittedParameters[min_index,:], 100*(rep/maxrestart),fitId, agentMemory, mappingX, vposteriors\n",
    "      except Exception as e:\n",
    "        print(\"Final fit selection failed:\", e)\n",
    "        print(\"Terminal error (presumably failed fit): \", e, flush=True)\n",
    "        return np.nan, np.nan, np.nan, np.nan, fittedParameters[0,:], 100*rep/maxrestart,fitId, pd.DataFrame(), {}, vposteriors,\n",
    "    \n",
    "    if parallel_job==False:\n",
    "        result_jobs=[]\n",
    "        with tqdm(total=len(participants)) as pbar:\n",
    "            for fitId in participants:\n",
    "                resultjob=pyBADSparallel_func(fitId)\n",
    "                result_jobs.append(resultjob)\n",
    "                pbar.update(1)\n",
    "        time.sleep(10)\n",
    "    else:\n",
    "        if parallel_mode=='joblib':\n",
    "            result_jobs=Parallel(n_jobs=40)(delayed(pyBADSparallel_func)(fitId) for fitId in participants)\n",
    "            batchdf = pd.DataFrame(list(result_jobs), columns=[\"bestNLL\", \"bestAIC\", \"bestBIC\", \"priorNLL\", \"fitParameters\", \"fitSuccess\",\"fitId\", \"fitMemory\", \"mappingX\", \"VP\"])     \n",
    "            batchdf[\"fitAgent\"]=model_list[m]['name']\n",
    "            batchdf.to_pickle(os.path.join(fit_folder, model_list[m]['name'] + '.pkl'))\n",
    "            with open(os.path.join(fit_folder, model_list[m]['name'] + '_info.pkl'), 'wb') as handle:\n",
    "                pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                print('files saved', flush=True)\n",
    "            results_df=pd.concat([results_df, batchdf])\n",
    "        elif parallel_mode=='slurm':\n",
    "            now = datetime.now()\n",
    "            compact_str = now.strftime(\"%m%d%H%M\")\n",
    "            fit_logfolder=os.path.join(fit_folder,'slurm_logs', model['name'],compact_str)\n",
    "            if not os.path.isdir(fit_logfolder):\n",
    "                os.makedirs(fit_logfolder)\n",
    "            executor = submitit.SlurmExecutor(folder=fit_logfolder, max_num_timeout=5)\n",
    "            executor.update_parameters(mem=3000, time=7000, partition =\"CPU\", cpus_per_task=2, signal_delay_s=300)\n",
    "            unordered_results=[]\n",
    "            returning_order=[]\n",
    "            nreturned=0\n",
    "            modeljobs = []\n",
    "            with tqdm(total=len(participants), desc=f\"Submitting jobs {model['name']}...\") as pbar:\n",
    "                for fitId in participants:\n",
    "                    submititjob = executor.submit(pyBADSparallel_func, fitId)\n",
    "                    modeljobs.append(submititjob)\n",
    "                    time.sleep(0.25)\n",
    "                    pbar.update(1)\n",
    "            time.sleep(1)\n",
    "            modeljobs_id={job.job_id: idx for idx, job in enumerate(modeljobs)}\n",
    "            massive_jobstruct.append(modeljobs)\n",
    "            massive_jobs_id.append(modeljobs_id)\n",
    "            massive_jobs_count+=len(modeljobs_id)\n",
    "            print(f'finished computation of {model_list[m][\"name\"]}', flush=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
