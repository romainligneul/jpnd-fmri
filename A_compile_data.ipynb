{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "Subject 1bis is a duplicate of subject 1, added for development purposes\n",
    "\n",
    "Subject 1 does not seem to have missed prediction trials. Unsure how things should work if this were to happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set some useful metadata\n",
    "metadata={\n",
    "  'dataset_name': 'dev',\n",
    "  'folder_logfiles': 'logfiles',\n",
    "  'included_participants': ['1', '1bis'],\n",
    "  'included_sessions': ['1','2'],\n",
    "  'included_runs': ['1','2','3'],  \n",
    "  'folder_compiled_data': 'compiled_data',\n",
    "  'SAmap': [[1,2],[0,2],[0,1]]\n",
    "}\n",
    "\n",
    "prediction_columns=['trial_num','state_side','correct_resp','state_choice','P_key_resp.keys','P_fixation.started','P_ITI.started','feedback',\n",
    "                    'P_state.started','P_action.started', 'P_state_choice_L.started','P_state_choice_R.started',\n",
    "                    'P_key_resp.started','P_fixation.stopped','P_feedback_img.started', 'Accuracy','P_choice_box.started','P_key_resp.rt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 missed exploration trials 1_1_1\n",
      "1 missed exploration trials 1_1_3\n",
      "Warning, 1 prediction trial missing in 1_2_2\n",
      "Accepting for now, assuming the last prediction responses was/were not recorded...\n",
      "Warning, 1 prediction trial missing in 1_2_3\n",
      "Accepting for now, assuming the last prediction responses was/were not recorded...\n",
      "4 missed exploration trials 1bis_1_1\n",
      "1 missed exploration trials 1bis_1_3\n",
      "Warning, 1 prediction trial missing in 1bis_2_2\n",
      "Accepting for now, assuming the last prediction responses was/were not recorded...\n",
      "Warning, 1 prediction trial missing in 1bis_2_3\n",
      "Accepting for now, assuming the last prediction responses was/were not recorded...\n"
     ]
    }
   ],
   "source": [
    "## Initialize dataframe\n",
    "df_full=pd.DataFrame()\n",
    "\n",
    "## Loop over expected logfiles\n",
    "for pix, pid in enumerate(metadata['included_participants']):\n",
    "  \n",
    "  for six, sid in enumerate(metadata['included_sessions']):\n",
    "    \n",
    "    for rix, rid in enumerate(metadata['included_runs']):\n",
    "      \n",
    "      # get file\n",
    "      filepath_base=os.path.join(metadata['folder_logfiles'], f'{pid}_{sid}_{rid}_EP_task*.csv')\n",
    "      filepath=glob.glob(filepath_base)\n",
    "      #\n",
    "      assert len(filepath)==1, f'There should be only one file matching {filepath_base}'\n",
    "      #\n",
    "      df_run=pd.read_csv(filepath[0])\n",
    "      df_predict=df_run[prediction_columns].copy(deep=True)\n",
    "      df_predict=df_predict[df_predict['P_key_resp.keys'].isna()==False].reset_index(drop=True)\n",
    "      # clean up\n",
    "      df_run=df_run[df_run['E_catch.thisTrialN'].isna()==False].reset_index(drop=True)\n",
    "      # add r\n",
    "      prediction_index=np.where(df_run['trial_tag_bool']==1)[0]\n",
    "      if prediction_index.shape[0]>df_predict.values.shape[0]:\n",
    "        print(f'Warning, {prediction_index.shape[0]-df_predict.values.shape[0]} prediction trial missing in {pid}_{sid}_{rid}')\n",
    "        print(f'Accepting for now, assuming the last prediction responses was/were not recorded...')\n",
    "\n",
    "      df_run.loc[prediction_index[:df_predict.values.shape[0]],prediction_columns]=df_predict.values\n",
    "\n",
    "      df_run['missedExplore']=0\n",
    "      repeatedExplore_ind=np.where(df_run['E_catch.thisN'].diff()>0)[0]-1\n",
    "      if repeatedExplore_ind.shape[0]>0:\n",
    "        df_run.loc[repeatedExplore_ind,'missedExplore']=1\n",
    "        print(f'{repeatedExplore_ind.shape[0]} missed exploration trials {pid}_{sid}_{rid}')\n",
    "      \n",
    "      df_run['missedPredict']=0\n",
    "      repeatedPredict_ind=np.where(df_run['P_catch.thisN'].diff()>0)[0]-1\n",
    "      if repeatedPredict_ind.shape[0]>0:\n",
    "        df_run.loc[repeatedPredict_ind,'missedPredict']=1    \n",
    "        print(f'{repeatedPredict_ind.shape[0]} missed prediction trials {pid}_{sid}_{rid}')  \n",
    "\n",
    "      df_run['missed']=df_run['missedExplore']+df_run['missedPredict']\n",
    "\n",
    "      df_run['participant']=pid\n",
    "      df_full=pd.concat([df_full,df_run],axis=0,ignore_index=True).reset_index(drop=True)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recover actions (Crule: A0=>1, A1=>2,A2=>3)\n",
    "cols_to_int = ['trial_tag_bool', 'action_side', 'current_state','prediction_targets_end','prediction_state','current_rule','Accuracy','feedback','E_key_resp.keys', 'state_choice']\n",
    "df_full[cols_to_int] = df_full[cols_to_int].fillna(-1).astype(int)\n",
    "\n",
    "rules=[\n",
    "  [\n",
    "  [1,1,1],\n",
    "  [2,2,2],\n",
    "  [0,0,0],\n",
    "  ],\n",
    "  [\n",
    "  [0,1,2],\n",
    "  [0,1,2],\n",
    "  [0,1,2],\n",
    "  ],  \n",
    "]\n",
    "\n",
    "df_full['action']=-1\n",
    "df_full['next_state']=-1\n",
    "\n",
    "for ix, row in df_full.iterrows():\n",
    "  \n",
    "  if row['trial_tag_bool']==0 and row['missed']==0:\n",
    "    if row['action_side']==1:\n",
    "      df_full.loc[ix,'action']=metadata['SAmap'][row['current_state']-1][row['E_key_resp.keys']-1]\n",
    "    else:\n",
    "      df_full.loc[ix,'action']=metadata['SAmap'][row['current_state']-1][1-(row['E_key_resp.keys']-1)]\n",
    "    if df_full.loc[ix+1,'trial_tag_bool']==0:\n",
    "      df_full.loc[ix,'next_state']=df_full.loc[ix+1,'current_state']-1\n",
    "  elif row['trial_tag_bool']==1 and row['missed']==0:\n",
    "    df_full.loc[ix,'action']=df_full.loc[ix,'prediction_targets_end']-1\n",
    "    df_full.loc[ix,'next_state']=rules[row['current_rule']][row['prediction_state']-1][row['prediction_targets_end']-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['state']=df_full['current_state'].values\n",
    "df_full.loc[df_full['prediction_state']>=0,'state']=df_full.loc[df_full['prediction_state']>=0,'prediction_state'].values-1\n",
    "\n",
    "df_full['reward']=np.nan\n",
    "df_full.loc[df_full['feedback']==1,'R']=df_full.loc[df_full['feedback']==1,'Accuracy'].values\n",
    "\n",
    "df_full['newblock']=0\n",
    "df_full.loc[df_full.trial_num==0,'newblock']=1\n",
    "\n",
    "df_full['action']=df_full['action'].astype(int)\n",
    "df_full['next_state']=df_full['next_state'].astype(int)\n",
    "df_full['visit']=df_full['visit'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -1\n",
       "1      -1\n",
       "2      -1\n",
       "3      -1\n",
       "4      -1\n",
       "       ..\n",
       "1455   -1\n",
       "1456   -1\n",
       "1457   -1\n",
       "1458    3\n",
       "1459    3\n",
       "Name: prediction_state, Length: 1460, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full['prediction_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check, prediction in controllable rule\n",
      "prediction_state  prediction_targets_end  state_choice\n",
      "1                 2                        2              1.0\n",
      "                                           3              0.0\n",
      "                  3                        2              0.0\n",
      "                                           3              1.0\n",
      "2                 1                        1              1.0\n",
      "                                           3              0.0\n",
      "                  3                        1              0.0\n",
      "                                           3              1.0\n",
      "3                 1                       -1             -1.0\n",
      "                                           1              1.0\n",
      "                  2                       -1             -1.0\n",
      "                                           1              0.0\n",
      "                                           2              1.0\n",
      "Name: Accuracy, dtype: float64\n",
      "Sanity check, prediction in uncontrollable rule\n",
      "prediction_state  prediction_targets_end  state_choice\n",
      "1                 2                       2               1.0\n",
      "                                          3               0.0\n",
      "                  3                       2               1.0\n",
      "                                          3               0.0\n",
      "2                 1                       1               0.0\n",
      "                                          3               1.0\n",
      "                  3                       1               0.0\n",
      "                                          3               1.0\n",
      "3                 1                       1               1.0\n",
      "                  2                       1               1.0\n",
      "                                          2               0.0\n",
      "Name: Accuracy, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Sanity check, prediction in controllable rule\")\n",
    "print(df_full[(df_full['trial_tag_bool']==1) & (df_full['current_rule']==1)].groupby(['prediction_state','prediction_targets_end','state_choice'])['Accuracy'].mean())\n",
    "print(\"Sanity check, prediction in uncontrollable rule\")\n",
    "print(df_full[(df_full['trial_tag_bool']==1) & (df_full['current_rule']==0)].groupby(['prediction_state','prediction_targets_end','state_choice'])['Accuracy'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(metadata['folder_compiled_data'],metadata['dataset_name']),exist_ok=True)\n",
    "df_full.to_pickle(os.path.join(metadata['folder_compiled_data'],metadata['dataset_name'], 'dataset.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(metadata['folder_compiled_data'],metadata['dataset_name'], 'metadata.pkl'), 'wb') as f:\n",
    "    pickle.dump(metadata, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
